{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1023a646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from evtk.hl import imageToVTK\n",
    "import nrrd\n",
    "from scipy.stats import iqr\n",
    "import vtk\n",
    "from vtk.util import numpy_support\n",
    "from vtkmodules.vtkCommonDataModel import vtkStructuredPoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "521c42f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tangle function\n",
    "\n",
    "x = np.linspace(-5, 5, num=64)\n",
    "y = np.linspace(-5, 5, num=64)\n",
    "z = np.linspace(-5, 5, num=64)\n",
    "\n",
    "XX, YY, ZZ = np.meshgrid(x, y, z)\n",
    "\n",
    "f = XX**4 - 5*XX**2 + YY**4 - 5*YY**2 + ZZ**4 - 5*ZZ**2 + 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02d6dcc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tm8/tusharathawale/research/projects/ECRP/inverseLinearInterpolationUncertaintyGaussian/code/python-code/prepare-data/tangle-data/output-usedby-other-code/recreate-TVCG-tangle-results/truth_tangle.vti'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write ground truth\n",
    "imageToVTK(\"./truth_tangle\", pointData = {\"tangle\" : f})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a028b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfectly correlated ensemble (i.e., correlation=1) with outlier members\n",
    "def getCorrelatedEnsemble(data, numMembers, numoutliers):\n",
    "    \n",
    "    h,w,d = data.shape\n",
    "    # 1 extra size to store variance / or kernel bandwidth\n",
    "    ensemble = np.zeros((numMembers+1,h, w, d))\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    \n",
    "    for i in range(numMembers - numOutliers):\n",
    "        \n",
    "        \n",
    "        factor = np.random.uniform(0.99,1.01,1)\n",
    "        \n",
    "        ensemble[i,:,:,:] = factor*data\n",
    "        \n",
    "        \n",
    "    for i in range(numMembers - numOutliers, numMembers):\n",
    "        \n",
    "        factor = np.random.uniform(1.03,1.07,1)\n",
    "    \n",
    "        ensemble[i,:,:,:] = factor*data\n",
    "        \n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d20ee991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the ensemble\n",
    "numMems = 5\n",
    "numOutliers = 1\n",
    "ensemble_correlated = getCorrelatedEnsemble(f, numMems, numOutliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63bb4450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to write out numpy array to vtk files\n",
    "\n",
    "def writeStructuredDs(fname, ds):\n",
    "    writer = vtk.vtkStructuredPointsWriter()\n",
    "    writer.SetFileName(fname)\n",
    "    writer.SetFileVersion(42)\n",
    "    writer.SetInputData(ds)\n",
    "    writer.Update()\n",
    "    writer.Write() \n",
    "\n",
    "\n",
    "# Write data with one field\n",
    "def writeOneField(fname, fieldname1, data1):\n",
    "    \n",
    "    a,b,c = data1.shape\n",
    "    \n",
    "    xdim=a\n",
    "    ydim=b\n",
    "    zdim=c\n",
    "\n",
    "    x,y,z = np.meshgrid(np.linspace(0,a,xdim), np.linspace(0,b,ydim), np.linspace(0,c,zdim), indexing='ij')\n",
    "    print(x.size, y.size, z.size)\n",
    "\n",
    "    structured_dataset = vtkStructuredPoints()\n",
    "    structured_dataset.SetDimensions(xdim, ydim, zdim)\n",
    "    structured_dataset.SetOrigin(0, 0, 0)\n",
    "    #print(np.array(g).shape)\n",
    "    \n",
    "    vtkArray1 = numpy_support.numpy_to_vtk(np.array(data1).flatten())\n",
    "    vtkArray1.SetNumberOfComponents(1)\n",
    "    vtkArray1.SetName(fieldname1)\n",
    "\n",
    "    structured_dataset.GetPointData().AddArray(vtkArray1)\n",
    "    structured_dataset.GetPointData().SetActiveScalars(fieldname1)\n",
    "\n",
    "    writeStructuredDs(fname,structured_dataset)\n",
    "\n",
    "# Write data with two fields\n",
    "# e.g.,writeTwoFields(\"uncertaintyBiVariateField.vtk\", \"minField\", minimumCurlZ, \"maxField\", maximumCurlZ)\n",
    "def writeTwoFields(fname, fieldname1, data1, fieldname2, data2):\n",
    "    \n",
    "    a,b,c = data1.shape\n",
    "    \n",
    "    xdim=a\n",
    "    ydim=b\n",
    "    zdim=c\n",
    "\n",
    "    x,y,z = np.meshgrid(np.linspace(0,a,xdim), np.linspace(0,b,ydim), np.linspace(0,c,zdim), indexing='ij')\n",
    "    print(x.size, y.size, z.size)\n",
    "\n",
    "    structured_dataset = vtkStructuredPoints()\n",
    "    structured_dataset.SetDimensions(xdim, ydim, zdim)\n",
    "    structured_dataset.SetOrigin(0, 0, 0)\n",
    "    #print(np.array(g).shape)\n",
    "    \n",
    "    vtkArray1 = numpy_support.numpy_to_vtk(np.array(data1).flatten())\n",
    "    vtkArray1.SetNumberOfComponents(1)\n",
    "    vtkArray1.SetName(fieldname1)\n",
    "    \n",
    "    vtkArray2 = numpy_support.numpy_to_vtk(np.array(data2).flatten())\n",
    "    vtkArray2.SetNumberOfComponents(1)\n",
    "    vtkArray2.SetName(fieldname2)\n",
    "\n",
    "\n",
    "    structured_dataset.GetPointData().AddArray(vtkArray1)\n",
    "    structured_dataset.GetPointData().SetActiveScalars(fieldname1)\n",
    "    \n",
    "    structured_dataset.GetPointData().AddArray(vtkArray2)\n",
    "    structured_dataset.GetPointData().SetActiveScalars(fieldname2)\n",
    "\n",
    "    writeStructuredDs(fname,structured_dataset)\n",
    "    \n",
    "# Write data with five fields\n",
    "def writeFiveFields(fname, fieldname1, data1, fieldname2, data2, fieldname3, data3, fieldname4, data4, fieldname5, data5):\n",
    "    \n",
    "    a,b,c = data1.shape\n",
    "    \n",
    "    xdim=a\n",
    "    ydim=b\n",
    "    zdim=c\n",
    "\n",
    "    x,y,z = np.meshgrid(np.linspace(0,a,xdim), np.linspace(0,b,ydim), np.linspace(0,c,zdim), indexing='ij')\n",
    "    print(x.size, y.size, z.size)\n",
    "\n",
    "    structured_dataset = vtkStructuredPoints()\n",
    "    structured_dataset.SetDimensions(xdim, ydim, zdim)\n",
    "    structured_dataset.SetOrigin(0, 0, 0)\n",
    "    #print(np.array(g).shape)\n",
    "    \n",
    "    vtkArray1 = numpy_support.numpy_to_vtk(np.array(data1).flatten())\n",
    "    vtkArray1.SetNumberOfComponents(1)\n",
    "    vtkArray1.SetName(fieldname1)\n",
    "    \n",
    "    vtkArray2 = numpy_support.numpy_to_vtk(np.array(data2).flatten())\n",
    "    vtkArray2.SetNumberOfComponents(1)\n",
    "    vtkArray2.SetName(fieldname2)\n",
    "    \n",
    "    vtkArray3 = numpy_support.numpy_to_vtk(np.array(data3).flatten())\n",
    "    vtkArray3.SetNumberOfComponents(1)\n",
    "    vtkArray3.SetName(fieldname3)\n",
    "    \n",
    "    vtkArray4 = numpy_support.numpy_to_vtk(np.array(data4).flatten())\n",
    "    vtkArray4.SetNumberOfComponents(1)\n",
    "    vtkArray4.SetName(fieldname4)\n",
    "\n",
    "    vtkArray5 = numpy_support.numpy_to_vtk(np.array(data5).flatten())\n",
    "    vtkArray5.SetNumberOfComponents(1)\n",
    "    vtkArray5.SetName(fieldname5)\n",
    "\n",
    "    structured_dataset.GetPointData().AddArray(vtkArray1)\n",
    "    structured_dataset.GetPointData().SetActiveScalars(fieldname1)\n",
    "    \n",
    "    structured_dataset.GetPointData().AddArray(vtkArray2)\n",
    "    structured_dataset.GetPointData().SetActiveScalars(fieldname2)\n",
    "\n",
    "    structured_dataset.GetPointData().AddArray(vtkArray3)\n",
    "    structured_dataset.GetPointData().SetActiveScalars(fieldname3)\n",
    "    \n",
    "    structured_dataset.GetPointData().AddArray(vtkArray4)\n",
    "    structured_dataset.GetPointData().SetActiveScalars(fieldname4)\n",
    "    \n",
    "    structured_dataset.GetPointData().AddArray(vtkArray5)\n",
    "    structured_dataset.GetPointData().SetActiveScalars(fieldname5)\n",
    "    \n",
    "    writeStructuredDs(fname,structured_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdeb3c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262144 262144 262144\n"
     ]
    }
   ],
   "source": [
    "# Data for the independent Gaussian model.\n",
    "meanVol = np.mean(ensemble_correlated[0:numMems,:,:,:], axis=0)\n",
    "varVol = np.var(ensemble_correlated[0:numMems,:,:,:], axis=0)\n",
    "writeTwoFields(\"./tangle-ignore-correlation.vtk\", \"mean\", meanVol, \"variance\", varVol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d01f085b-887c-4412-88aa-70f280732c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262144 262144 262144\n"
     ]
    }
   ],
   "source": [
    "# Data for the independent uniform model.\n",
    "minVol = np.amin(ensemble_correlated[0:numMems,:,:,:], axis=0)\n",
    "maxVol = np.amax(ensemble_correlated[0:numMems,:,:,:], axis=0)\n",
    "\n",
    "meanUniformVol = (minVol+maxVol)/2\n",
    "widthUniformVol = maxVol - meanUniformVol\n",
    "writeTwoFields(\"./tangle-independent-uniform.vtk\", \"mean\", meanUniformVol, \"variance\", widthUniformVol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b39cbb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262144 262144 262144\n"
     ]
    }
   ],
   "source": [
    "# Data for the Gaussian model with spatial correlation. Pack mean, variance, rhoX, rhoY, and rhoZ fields into a single vtk file\n",
    "\n",
    "numMems = 6\n",
    "\n",
    "meanVol = np.mean(ensemble_correlated[0:numMems,:,:,:], axis=0)\n",
    "\n",
    "# Compute correlation in X, Y, and Z directions\n",
    "rhoX = np.zeros((64,64,64))\n",
    "rhoY = np.zeros((64,64,64))\n",
    "rhoZ = np.zeros((64,64,64))\n",
    "varVol = np.zeros((64,64,64))\n",
    "\n",
    "for i in range(63):\n",
    "    for j in range(63):\n",
    "        for k in range(63):\n",
    "            \n",
    "            #****** np.var and np.covar can lead to slightly different variance value computation\n",
    "\n",
    "            # Compute covariance in x direction\n",
    "            x1 = ensemble_correlated[0:numMems,i,j,k]\n",
    "            x2 = ensemble_correlated[0:numMems,i+1,j,k]\n",
    "            X = np.stack((x1, x2), axis=0)\n",
    "            rhoXMat = np.cov(X)\n",
    "            rhoX[i,j,k] = rhoXMat[0,1]\n",
    "            \n",
    "            # Compute covariance in y direction\n",
    "            y1 = ensemble_correlated[0:numMems,i,j,k]\n",
    "            y2 = ensemble_correlated[0:numMems,i,j+1,k]\n",
    "            Y = np.stack((y1, y2), axis=0)\n",
    "            rhoYMat = np.cov(Y)\n",
    "            rhoY[i,j,k] = rhoYMat[0,1]\n",
    "            \n",
    "            # Compute covariance in z direction\n",
    "            z1 = ensemble_correlated[0:numMems,i,j,k]\n",
    "            z2 = ensemble_correlated[0:numMems,i,j,k+1]\n",
    "            Z = np.stack((z1, z2), axis=0)\n",
    "            rhoZMat = np.cov(Z)\n",
    "            rhoZ[i,j,k] = rhoZMat[0,1]\n",
    "            \n",
    "            varVol[i,j,k] = rhoXMat[0,0]\n",
    "            \n",
    "            if(i==62):\n",
    "                varVol[i+1,j,k] = np.var(ensemble_correlated[0:numMems,i+1,j,k], axis=0)\n",
    "            if(j==62):\n",
    "                varVol[i,j+1,k] = np.var(ensemble_correlated[0:numMems,i,j+1,k], axis=0) \n",
    "            if(k==62):\n",
    "                varVol[i,j,k+1] = np.var(ensemble_correlated[0:numMems,i,j,k+1], axis=0)    \n",
    "                \n",
    "\n",
    "writeFiveFields(\"./14-mems-tangle-consider-correlation.vtk\", \"mean\", meanVol, \"variance\", varVol, \"rhoX\", rhoX, \"rhoY\", rhoY, \"rhoZ\", rhoZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1b2114f-0964-41cc-b12d-aa01be745c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262144 262144 262144\n",
      "262144 262144 262144\n",
      "262144 262144 262144\n",
      "262144 262144 262144\n",
      "262144 262144 262144\n",
      "262144 262144 262144\n",
      "262144 262144 262144\n",
      "262144 262144 262144\n",
      "262144 262144 262144\n",
      "262144 262144 262144\n",
      "262144 262144 262144\n",
      "262144 262144 262144\n",
      "262144 262144 262144\n",
      "262144 262144 262144\n"
     ]
    }
   ],
   "source": [
    "# Save the data for kernel density estimation (KDE) as individual vtk ensmeble members for viskores code\n",
    "for i in range(numMems):\n",
    "        ensembleMember = np.squeeze(ensemble_correlated[i,:,:,:])\n",
    "        writeOneField('./tangle_correlation_one_'+str(i)+'.vtk', 'tangle', ensembleMember)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vector-field-vis",
   "language": "python",
   "name": "vector-field-vis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
